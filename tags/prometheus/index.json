[{"content":"装饰器是什么？ 装饰器是可调用的对象，其参数是另一个函数（被装饰的函数）。\n装饰器可能会处理被装饰的函数，然后把它返回，或者将其替换成另一个 函数或可调用对象。\nexamples import functools import time from threading import Thread def timer(func): def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) print(f\u0026#34;execute func {func.__name__}, params {args, kwargs}, time passed {time.time() - start}s\u0026#34;) return result return wrapper def retry(times=1, delay=0): def outer(func): @functools.wraps(func) def inner(*args, **kwargs): t = times while t: try: return func(*args, **kwargs) except Exception as e: t -= 1 time.sleep(delay) print(f\u0026#34;retry times: {times - t}, error: {e}, delay: {delay}\u0026#34;) if not t: raise e return inner return outer def log(text=\u0026#34;no log output\u0026#34;): def decorator(func): @functools.wraps(func) def wrapper(*args, **kwargs): print(f\u0026#34;{text}, {func.__name__}\u0026#34;) return func(*args, **kwargs) return wrapper return decorator def async_func(f): def wrapper(*args, **kwargs): thread = Thread(target=f, args=args, kwargs=kwargs) thread.setDaemon(True) thread.start() return thread return wrapper def main(): @timer @log(\u0026#34;this is a log\u0026#34;) def do_something(t): time.sleep(t) return t @retry(times=3) def division_by_zero(): return 1 / 0 print(do_something(0.5)) division_by_zero() @timer def test_async_func(): @async_func def A(): print(\u0026#34;现在在执行A函数\u0026#34;) print(\u0026#39;A函数睡眠3秒钟\u0026#39;) time.sleep(3) print(\u0026#34;A函数执行完毕\u0026#34;) return def B(): print(\u0026#34;现在在执行B函数\u0026#34;) A() B() if __name__ == \u0026#39;__main__\u0026#39;: test_async_func() print(\u0026#34;-\u0026#34;*156) main() references https://www.liaoxuefeng.com/wiki/1016959663602400/1017451662295584 https://www.zywvvd.com/notes/coding/python/asyncio/threading/ https://www.zywvvd.com/notes/coding/python/fluent-python/chapter-7/python-decorate/python-decorate/ ","description":"…","id":0,"section":"posts","tags":["questions","python"],"title":"Python装饰器","uri":"https://puzzledstorm.github.io/posts/python-decorator/"},{"content":"1. 回溯算法 原理 全排列问题，3个数字的全排列。 ","description":"","id":1,"section":"posts","tags":["刷题"],"title":"Leetcode","uri":"https://puzzledstorm.github.io/posts/leetcode/"},{"content":"2023.02.08 questions 1. 视频编码原理[ffmpeg] 2. I帧，B帧，P帧, GOP是啥 3. yolo v5有多少层 4. 为什么要进行多轮训练，反复训练， 神经网络为什么要多轮训练 5. 残差网络是啥 6. 两个向量叉乘的物理意义 7. 贝叶斯公式，为什么要用贝叶斯公式？有啥用处？ 8. 马尔科夫链是啥？ personal answers 1. 待补充 2. I帧：帧内编码，关键帧。P帧：前向预测编码帧，记录本帧与前一关键帧的差别。B帧：双向预测帧，记录本帧与前后帧的差别。 GOP: group of picture, 两个I帧之间的距离。 3. 待补充 4. 多轮训练，通过设置较小学习率逐渐找到最优点。 5. 残差网络就是跳接，直接将网络层的原始输入结果合并到结果中，防止增加网络层反而有害的情况 6. 两个向量叉乘是这两个向量形成平面的法向量。 7. 贝叶斯公式，条件概率公式。用统计学的方法解释不同事件的先验概率和后验概率的量化关系计算问题。 8. 马尔科夫链，利用状态转移矩阵得到状态概率 ","description":"this is a question","id":2,"section":"posts","tags":["questions"],"title":"To be or not to be ,this is a question","uri":"https://puzzledstorm.github.io/posts/to-be-or-not-to-be-this-is-a-question/"},{"content":"从远程机器上查找文件 1 find / -name \u0026#34;target file\u0026#34; 远程scp 1 scp -r root@host:/mnt/xx.txt /mnt/ 用python实现上述功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 import paramiko from scp import SCPClient from pathlib import Path import os import yaml root = Path(__file__).parent config_path = f\u0026#34;{root}/deploy.config.yml\u0026#34; with open(config_path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: config = yaml.safe_load(f) # print(config) class Model(object): def __init__(self, host=\u0026#34;your host\u0026#34;, port=\u0026#34;22\u0026#34;, username=\u0026#34;root\u0026#34;, password=\u0026#34;your password\u0026#34;): self.host = host self.port = port self.username = username self.password = password def find(self, target): # 创建SSHClient 实例对象 ssh = paramiko.SSHClient() # 调用方法，表示没有存储远程机器的公钥，允许访问 ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) # 连接远程机器，地址，端口，用户名密码 ssh.connect(self.host, self.port, self.username, self.password, timeout=10) # 输入linux命令 cmd = f\u0026#34;find / -name {target}\u0026#34; # ls = \u0026#34;ls\u0026#34; stdin, stdout, stderr = ssh.exec_command(cmd) # 输出命令执行结果 result = stdout.read() r = result.decode(\u0026#34;utf-8\u0026#34;) print(result) try: t = r.split(\u0026#34;\\n\u0026#34;)[0] except Exception as e: print(f\u0026#34;error: {e}\u0026#34;) t = None # 关闭连接 ssh.close() return t def scp(self, remote_file, local_path=None): ssh_client = paramiko.SSHClient() ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy) ssh_client.connect(self.host, self.port, self.username, self.password) scp_client = SCPClient(ssh_client.get_transport(), socket_timeout=15.0) file_path_lo = local_path or os.path.dirname(os.path.realpath(__file__)) file_path_re = remote_file print(file_path_lo) print(file_path_re) try: scp_client.get(file_path_re, file_path_lo) # 从服务器中获取文件 except FileNotFoundError as e: print(e) print(\u0026#34;system could not find the specified file\u0026#34; + local_path) result = \u0026#34;system could not find the specified file\u0026#34; + local_path else: print(\u0026#34;File downloaded successfully\u0026#34;) result = \u0026#34;File downloaded successfully\u0026#34; ssh_client.close() return result def download(self, remote_target, local_path): remote_tar = self.find(remote_target) if remote_tar is not None: self.scp(remote_tar, local_path) else: print(f\u0026#34;{remote_target} not found\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: m = Model() remote_target = \u0026#34;xxx.json\u0026#34; m.download(remote_target, os.getcwd()) self = __file__ os.remove(self) ","description":"从服务器上查找文件然后复制文件到本地机器","id":3,"section":"posts","tags":["python","scp"],"title":"从服务器上查找文件然后复制文件到本地机器","uri":"https://puzzledstorm.github.io/posts/pytho-find-scp/"},{"content":"监控环境搭建 需要以下组件：\ndocker prometheus node-exporter cadvisor grafana docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 version: \u0026#34;3.3\u0026#34; networks: monitor: driver: bridge services: node-exporter: image: prom/node-exporter:latest container_name: \u0026#34;node-exporter0\u0026#34; ports: - \u0026#34;9130:9100\u0026#34; restart: always networks: - monitor cadvisor: image: google/cadvisor:latest container_name: \u0026#34;cadvisor0\u0026#34; restart: always volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro ports: - \u0026#34;8081:8080\u0026#34; networks: - monitor prometheus: image: prom/prometheus:latest container_name: \u0026#34;prometheus0\u0026#34; restart: always ports: - \u0026#34;9097:9090\u0026#34; volumes: - \u0026#34;./prometheus.yml:/etc/prometheus/prometheus.yml\u0026#34; - \u0026#34;./prometheus_data:/prometheus\u0026#34; networks: - monitor grafana: image: grafana/grafana container_name: \u0026#34;grafana0\u0026#34; ports: - \u0026#34;3005:3000\u0026#34; restart: always volumes: - \u0026#34;./grafana_data:/var/lib/grafana\u0026#34; - \u0026#34;./grafana_log:/var/log/grafana\u0026#34; - \u0026#34;./grafana_data/crypto_data:/crypto_data\u0026#34; networks: - monitor prometheus.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 global: scrape_interval: 15s # 默认抓取周期 external_labels: monitor: \u0026#39;codelab-monitor\u0026#39; scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [\u0026#39;172.16.139.24:9097\u0026#39;, \u0026#39;172.16.139.24:8081\u0026#39;] - job_name: \u0026#39;node-exporter\u0026#39; #服务的名称 scrape_interval: 5s metrics_path: /metrics #获取指标的url static_configs: - targets: [\u0026#39;172.16.139.24:9130\u0026#39;] # 这个为监听指定服务服务的ip和port，需要修改为自己的ip,不能使用localhost和127.0.0.1 - job_name: \u0026#34;cadvisor\u0026#34; static_configs: - targets: - \u0026#39;172.16.139.24:8081\u0026#39; 启动 1 docker-compose up -d 结果如下：\n检查 浏览器访问\nnode-exporter http://172.16.139.24:9130/metrics\ncadvisor http://172.16.139.24:8081/containers/\nprometheus http://172.16.139.24:9097/targets\ngrafana http://172.16.139.24:3005/login\n用户名/密码 admin/admin\n操作：\n添加数据源\nConfiguration下\nAdd data source\nurl填上：http://172.16.139.24:9097\nSave \u0026amp; test\n导入面板\nid： 10619\nDocker Container \u0026amp; Host Metrics\n结果\n参考 https://grafana.com/grafana/dashboards/893-main/ https://www.jianshu.com/p/cb50ffe0b6b0 https://www.jianshu.com/p/bd64a114aab0 https://www.cnblogs.com/augus007/articles/9225431.html https://juejin.cn/post/6969764486701924383 https://blog.csdn.net/An1090239782/article/details/102999721 https://grafana.com/dashboards?search=docker https://www.gbmb.org/mib-to-mb ","description":"用grafana展示容器内存使用情况","id":4,"section":"posts","tags":["docker","grafana","cadvisor","prometheus","node-exporter"],"title":"监控机器上的docker容器","uri":"https://puzzledstorm.github.io/posts/monitor-docker-containers/"},{"content":"获取一个视频的所有帧 解码一个视频有多种方式，这里分别用pyav和opencv做示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 \u0026#34;\u0026#34;\u0026#34; decoder.py Destination: decode a video, get all frames Some documents： http://ffmpeg.org/documentation.html \u0026#34;\u0026#34;\u0026#34; import os import os.path as osp import shutil import time import uuid import av import cv2 class Decoder(object): def __init__(self): super(Decoder, self).__init__() @staticmethod def av_decoder(path_to_video, frame_dir=\u0026#34;frames/\u0026#34;): \u0026#34;\u0026#34;\u0026#34; PyAV document: https://pyav.org/docs/stable/index.html https://pyav.org/docs/stable/cookbook/numpy.html Returns: \u0026#34;\u0026#34;\u0026#34; # 解码获取视频帧并转换np数组 container = av.open(path_to_video) container.streams.video[0].thread_type = \u0026#34;AUTO\u0026#34; np_frames = [] for frame in container.decode(video=0): print(frame) array = frame.to_ndarray(format=\u0026#34;bgr24\u0026#34;) np_frames.append(array) container.close() print(len(np_frames)) print(np_frames[0].shape) return np_frames @staticmethod def cv2_decoder(path_to_video, frame_dir=\u0026#34;frames/\u0026#34;): \u0026#34;\u0026#34;\u0026#34; opencv-python document: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html Returns: \u0026#34;\u0026#34;\u0026#34; cap = cv2.VideoCapture(path_to_video) np_frames = [] while cap.isOpened(): ret, frame = cap.read() if not ret: break print(\u0026#39;read a new frame\u0026#39;) np_frames.append(frame) cap.release() print(len(np_frames)) print(np_frames[0].shape) return np_frames 编码所有帧 同样地分别用上述两种方法来做。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 \u0026#34;\u0026#34;\u0026#34; encoder.py Destination: encode a video, only with video stream Some documents： http://ffmpeg.org/documentation.html \u0026#34;\u0026#34;\u0026#34; import os import os.path as osp import shutil import time import cv2 import numpy as np import av import uuid from decoder import Decoder class Encoder(object): def __init__(self): super(Encoder, self).__init__() self.fps = 25 self.width = 1920 self.height = 1080 self.bit_rate = 8 * 1014 * 1024 def av_encoder(self, frames, encode_video): # 编码一个视频返回 container = av.open(encode_video, mode=\u0026#34;w\u0026#34;) stream = container.add_stream(\u0026#34;mpeg4\u0026#34;, rate=self.fps) container.streams.video[0].thread_type = \u0026#34;AUTO\u0026#34; stream.width = self.width stream.height = self.height stream.bit_rate = self.bit_rate stream.pix_fmt = \u0026#34;yuv420p\u0026#34; for frame in frames: frame = av.VideoFrame.from_ndarray(frame, format=\u0026#34;bgr24\u0026#34;) for packet in stream.encode(frame): container.mux(packet) # Flush stream for packet in stream.encode(): container.mux(packet) # Close the file container.close() print(f\u0026#34;{encode_video} encode complete\u0026#34;) def cv2_encoder(self, frames, encode_video): size = (self.width, self.height) fourcc = cv2.VideoWriter_fourcc(*\u0026#39;mp4v\u0026#39;) out = cv2.VideoWriter(encode_video, fourcc, self.fps, size) for frame in frames: out.write(frame) out.release() print(f\u0026#34;{encode_video} encode complete\u0026#34;) def av_set_parameter(self, video): with av.open(video) as container: stream = container.streams.video[0] self.fps = stream.codec_context.framerate # type :Fraction self.width = stream.codec_context.width self.height = stream.codec_context.height self.bit_rate = stream.bit_rate # video的码率 # all_bit_rate = container.bit_rate # 视频总码率 def cv2_set_parameter(self, video): cap = cv2.VideoCapture(video) self.fps = int(round(cap.get(cv2.CAP_PROP_FPS))) # 帧率 self.width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # 分辨率-宽度 self.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 分辨率-高度 # frame_counter = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) # 总帧数 # https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get # 2.4 can\u0026#39;t find bit rate # https://docs.opencv.org/5.x/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d # find it, but my opencv version can\u0026#39;t use it # self.bit_rate = int(cap.get(cv2.CAP_PROP_BITRATE)) cap.release() ","description":"如题所示","id":5,"section":"posts","tags":["encode"],"title":"How to encode a video by all frames","uri":"https://puzzledstorm.github.io/posts/how-to-encode-a-video-by-frames/"},{"content":"大概就是之前去了大熊猫繁殖基地，拍了几个视频。一直放在手机里太占内存了，而且我一直以来想学习一下剪辑，Pr或者达芬奇。\n这次终于有机会了，虽然主观意愿也不是很强烈。\n视频我没有太多剪辑，直接放到b站上了。\n\u0026mdash;\u0026mdash;分割线\u0026mdash;\u0026mdash;-\n2023.3.11更新\n之前大熊猫的视频一直懒得放，趁着今天开始认真学习达芬奇，就是b站影视飓风的达芬奇教程，又想起来，干脆就放上来。\n大熊猫，嘿嘿\n达芬奇学习笔记 参考：影视飓风达芬奇教程\n剪辑视频的完整流程👀 tim讲得非常清楚，反复观看的效果会非常好。\n达芬奇创建项目，项目命名保存，设置项目帧率(确定以后不可以修改)，设置参数自动保存，备份。 导入素材并进行分类-\u0026gt;粗剪-\u0026gt;精剪-\u0026gt;效果制作-\u0026gt;调色-\u0026gt;调音-\u0026gt;导出。 媒体面板-\u0026gt;快编面板-\u0026gt;剪辑面板-\u0026gt;Fusion面板-\u0026gt;调色面板-\u0026gt;Fairlight面板-\u0026gt;交付面板。 媒体面板 pass\n快编面板👀 Davinci快编面板，适合粗剪。 特点，不同于剪辑面板时间线监视器+素材监视器，只有一个监视器；媒体池、效果、标题，都被收起，保证超大时间线。播放头不动，双时间线看总览； 快编面板 - 模型：虚拟磁带，按顺序读取，线性剪辑。 1.母带监督 源磁带：母带+白线，标记各个素材出入点； 筛选素材：相对于每个素材io，拖时间，再到媒体池io拖时间线 （从头播放）；回放io、插入、继续播放、在io，快速预览大量素材（连续播放），不把时间浪费在重复操作上面； 每个媒体夹，就会生成一个母带；总文件是总母带； 2.更改素材分布 筛选母带的排序、设备机型、拍摄时间等； 列表模式，更多改排序的项； 理念：随着需求智能能改变的灵活时间线； 3.快速预览模式：检测素材长短，用均衡素材预览时间线。 短素材常速播放； 长素材快速播放； 4.插入模式： 智能插入：播放头靠前靠后，箭头提示加入位置； 附加：加到时间线尾部； 覆盖：放到上方轨道； 5.特写功能： 选中时间线素材，Ai引擎，检测面部，人脸，就进行自动缩放，不需要手动构图、规避跳切； 6.无聊按钮： 多久没有Broll会比较无趣，提示加broll的位置； 7.检查器： 整合到播放器的旁边 8.自动调色：选素材按下C 适合做粗剪、实效性的内容，没有精细调色时间 右上角 - 点击快速导出，就可以直接导出； 剪辑面板👀 先导入所有素材到媒体池，然后对视频进行分类，在素材监视器进行素材筛选。 在素材监视器上，给素材添加入出点(快捷键I/O)，直接可以把该入出点的视频分段拖进时间线或者是准备好的时间线中。 Alt加鼠标滚轮，缩放时间线。或者Ctrl +/Ctrl - 代理文件👀 1.媒体优化 【播放-代理模式】选择1/2或1/4进行回放 媒体优化文件的创建 【{媒体池}选中素材-点击右键-生成优化媒体文件】 【{时间线}选中素材-点击右键-生成媒体优化文件】 【文件-项目设置-主设置-优化的媒体和渲染缓存 编码可选DNXHR SQ 位置的选择】 临时换电脑 代理文件拷上去 【素材箱选中-重新找到优化媒体文件】 2.预渲染 【播放-渲染缓存-用户定义-时间线-选中卡顿片段{右键}-选择预渲染部分-渲染缓存{OFX滤镜}{调色}{Fusion}】 【播放-渲染缓存-{用户定义}改成{智能}】 智能媒体夹与双时间线剪辑👀 智能媒体文件夹 Aroll和Broll Aroii：主要的内容部分.讲话的片段.时间线的片段.代表了内容的核心框架.含有大量的信息。 Broll：帮助自己来表达自己的核心内容.而加上去的画面.比如说相机评测。当我讲到她某一样特性的时候，而加上去对应的画面。 快速区分Aroll和Broll.智能媒体夹功能：【媒体池-右键-智能媒体夹】：他就是一个自定义的高级搜索.可以直接在项目里筛选出.同一天拍摄的素材.同一个摄影机拍摄的素材.同一个场景拍摄的素材。 智能媒体夹功能的案例:素材的粗剪【媒体池-下拉栏-选择需要的媒体信息】 旗标：对于素材的快速定位.筛选所需的素材，右键打上旗标。 双时间线逻辑 {时间线.视频.音频.显示选项}：横向堆叠多个时间线.快速切换.点击时间线添加按钮.开启两条时间线. 两条时间线的作用：剪辑Aroll和Broll时在时间线剪辑.找到有价值的内容后.往上拉一条轨道【英文名叫Pull Up】.优点是快速区分出有价值内容.和目前还没有用过的内容. 假如说，你现在开始剪辑还是有素材被删掉了.把上面的轨道素材或者第二条轨道素材全部选中.拖到下面的时间线里面也是二号时间线里面.上面的时间线没有变化.下面时间线出来了，刚才挑选的素材 素材间隙的删除：【编辑-删除空隙】就可以删除时间线所有素材之间的间隙. 总结：双时间线剪辑.对于自媒体的流程.非常的有效.就像是拿了一个筛子.每次都拿一个滤网，层层筛选出最好的内容而不是零散的点击一个片段来播呀！然后再去寻找.Aroll完成之后.在开启一条Broll时间线.这样双时间线的优点会更加明显.快速的回放Aroll内容.然后根据内容选择上面的时间线.搜寻对应的Broll拉下来.就是整个视频的粗剪. 关于变速的一切👀 基本变速： 右键--更改片段速度--输入/拖动数值进行修改 （建议开启波纹序列和音调矫正） 备注：面对含有关键帧的素材--先右键复合片段（即pr的嵌套）--再进行变速 疑问：如何取消复合，不是CTRL+Z撤销操作 变速控制（CTRL+R）: 播放头移动到变速位置--点击速度--添加速度点--更改速度/拖动速度轴 备注：拖动速度轴-上边拉杆变速，下面控制片电脑变速的停止点。 线性变速转贝塞尔曲线变速： 右键--变速曲线--下拉选择重新调整变速-点击曲线 素材解释（升格视频）： 用于每秒多少帧的速率播放（单位是帧不是毫秒） 媒体池选中慢放素材--右键--片段属性--选择需要的回放帧率 帧采样： 让变速的画面更加流畅 项目设置--主设置--帧内插--最近、帧混合、光流法 备注：帧混合-借助前后帧混合出一个模糊的中间帧（用于快放），光流法--对比两帧之间像素的变化计算出一个新帧 单个片段设定： 选择片段--检查器--变速与缩放（运动估计-speedwarp变速） Fusion面板 pass\n调色面板 pass\nFairlight面板 pass\n交付面板 这个面板最简单，不用学都会。\n快捷键👀 快进，退，暂停：L/J/K 出入点：O/I F9 插入素材 ↑ ↓：跳跃至上/下剪辑点 ←→向后 前移动一帧 Shift＋←→：向后 前移动5帧 Ctrl＋/添加剪辑 Shift＋V选中片段 Shift＋[ ]修剪，同时按住Ctrl可以波纹剪辑 Shift＋delete 波纹删除 Alt＋↑↓ 上/下移动一个轨道 Ctrl＋T添加转场 Ctrl＋C复制属性，Alt＋V粘贴属性 D 关闭/启用片段 Ctrl＋R变速控制 Ctrl＋Shift＋L 链接片段(好像还有一个Ctrl＋Alt＋L) Shift＋Ctrl＋C 关键帧编辑器 Shift＋C曲线编辑器 F定位素材 Alt＋F媒体池定位 Ctrl＋A 全选素材 Alt＋Y向后选中所有素材 Alt＋Shift＋Y 向前选中所有素材 Ctrl＋F 全盘 Ctrl＋\u0026#34;＋，—\u0026#34;缩放时间线 Shift＋Z时间线总览 Alt＋Shift＋1.2.3 锁定轨道1.2.3 也可以换成F1,F2,F3锁定音频轨道 软件交互与工程打包👀 pr转达芬奇调色 pr-文件--导出--Final cut pto.xml--然后打开达芬奇--项目设置确定都正确--文件--导入时间线--导入aff,edl,xml--找到所需文件（如没有顺利链接：右键选中脱机素材-重新链接选中片段） 输出：交付面板-pr XML-选择编码（通常prores 422,LT windows-DNxHR SQ,DNxHR） 回到pr--导入达芬奇创建新的XML文件（逻辑上所有调色完成素材都会被重新连接，所以套底就直接完成） pr转ae 送到ae：素材右键-使用ae合成替换,或者是在pr导出 注意：这些交互有一个前提，不在双方软件加插件或复杂转场 总结：先锁定剪辑，再调色，再套底，最后再做复杂效果 达芬奇剪辑和ae的交互： 1.简单：选中片段-交付面板-导出素材-送到ae-再输出（就像视频文件一样） 2.好多片段：选中片段-交付面板-渲染-多个单独片段-添加到渲染队列 3.多片段不同位置：选中片段--文件---媒体文件管理--片段-转码（取决于你是否打算统一工程的编码）-位置-保留余量 媒体文件管理面板： 1.帮助归纳素材 2.打包所有素材， 例1.可选多个时间线-移动\\复制\\转码 2.整个项目-选择所有\\已使用文件 注意：只打包素材，不打包工程文件 打包工程文件：文件-导出项目文件-drp文件导出 备份：文件-项目管理器-mediastorm-点击备份按钮手动备份 若出现问题可按旁边恢复按钮找回数据库 若用新电脑剪辑：右键数据（local database）-找到文件夹-复制到移动硬盘-达芬奇-新建数据库-链接-选择位置-添加 秘传技👀 时间线智能媒体夹：达芬奇-偏好设置-用户-编辑-自动智能媒体夹时间线（从此所有时间线都会整齐排列） 时间线克隆：编辑-复制当前时间线（立刻多出备份） 时间线帧率更换：文件池右键--创建时间线--自定义设置--格式-将错误格式时间线复制（可单独设定每个时间线帧率） 项目克隆： 创建新工程-文件-项目设置（设置正确格式）-把每期视频都要用到的素材分类别放好--保存--有新项目要做时-在项目管理器ctrl+ c ctrl+v克隆一个素材（不需要再调整项目格式，模板功能）-重名名-开始创作 想回到之前文件状态时：激活了项目里的自动备份后--媒体管理器右键-备份项目-选择项目-加载（数据即可恢复） 选区跟随播放头：时间线-选区跟随播放头（效率高） 清理视频轨道：时间线-清理视频轨道-收起未使用片段 音响素材库：添加素材库-将收集好音响素材放入即可 显卡加速：1.达芬奇-偏好设置-系统-内存与GPU-GPU处理模式-CUDA加速 2.偏好设置-解码选项-全部打开和选中Debayer（earyDCP可关 弹幕说） RAW文件解码：若显卡还不足以支撑 文件-项目设置-cameea RAW-找到对应设定-解码质量调低 注意：导出时一定要记得调回来 （建议：驱动程序：设置成studio驱动程序） 快速加黑边：时间线-输出加黑边-选择遮幅比例（若为适配手机全面屏，需改变时间线分辨率1920＊960） 截图：调色面板-右键监视器-抓取经帧-图片出现在左侧-右键选择导出即可 将时间线每个片段都抓一张图：右键-抓取所有关键祯-导出 ","description":"学习一下如何用达芬奇把我拍的大熊猫视频剪出来","id":6,"section":"posts","tags":["达芬奇"],"title":"学习剪辑艺术","uri":"https://puzzledstorm.github.io/posts/davinci/"},{"content":"盯着这个页面发呆，真的不知道说点啥。\n说实话，以前我经常自我反思，思考的时间不能说很多，但是至少我有意识的在往思考的方向走。现在，连书都懒得看了。以前还天天刷知乎，现在整天刷着b站，看看搞笑鬼畜视频。\n有时候想想当个死肥宅也不错，看看纸片人也能开心，哪怕不及新垣结衣万分之一。\n多说无益，我打算不搞反思，要搞好玩开心的东西。\n","description":"Hugo, the world’s fastest framework for building websites","id":7,"section":"","tags":null,"title":"About","uri":"https://puzzledstorm.github.io/about/"}]